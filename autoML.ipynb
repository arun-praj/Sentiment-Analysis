{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from flaml import AutoML\r\n",
    "from lightgbm import LGBMClassifier\r\n",
    "from sklearn.ensemble import ExtraTreesClassifier\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.metrics import precision_score, recall_score,accuracy_score,f1_score,roc_curve,auc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "training_set = pd.read_csv(\"dataset/cleanedLabeledTrainData.csv\")\r\n",
    "\r\n",
    "Y=training_set['sentiment'].values\r\n",
    "X=training_set['review'].values\r\n",
    "\r\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42,stratify=Y)\r\n",
    "print (\"No. of Training Examples: \",x_train.shape)\r\n",
    "print (\"No. of Testing Examples: \",x_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No. of Training Examples:  (20000,)\n",
      "No. of Testing Examples:  (5000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tf=TfidfVectorizer(min_df=10,max_df=0.95,use_idf=True)\r\n",
    "\r\n",
    "tf.fit_transform(x_train)\r\n",
    "X_train=tf.transform(x_train) # for train data we can use fit_transfrom also.\r\n",
    "X_test=tf.transform(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "extr = ExtraTreesClassifier(criterion='entropy', max_features=0.7540240016109981,\r\n",
    "                     max_leaf_nodes=195, n_estimators=9, n_jobs=-1)\r\n",
    "extr.fit(X_train, y_train)\r\n",
    "y_pred = extr.predict(X_test)\r\n",
    "print(\"Accuracy: \",round(accuracy_score(y_test,y_pred),3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.788\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "lgbm = LGBMClassifier(colsample_bytree=0.8085131463835397,\r\n",
    "               learning_rate=0.03735454900037746, max_bin=256,\r\n",
    "               min_child_samples=33, n_estimators=4, num_leaves=4,\r\n",
    "               objective='binary', reg_alpha=0.0009765625,\r\n",
    "               reg_lambda=0.692397057684401, verbose=-1)\r\n",
    "lgbm.fit(X_train, y_train)\r\n",
    "y_pred = lgbm.predict(X_test)\r\n",
    "print(\"Accuracy: \",round(accuracy_score(y_test,y_pred),3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.692\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\r\n",
    "# Initialize an AutoML instance\r\n",
    "automl = AutoML()\r\n",
    "# Specify automl goal and constraint\r\n",
    "automl_settings = {\r\n",
    "    \"time_budget\": 200,  # in seconds\r\n",
    "    \"metric\": 'accuracy',\r\n",
    "    \"task\": 'classification',\r\n",
    "    # \"log_file_name\": \"test/iris.log\",\r\n",
    "}\r\n",
    "\r\n",
    "# Train with labeled input data\r\n",
    "automl.fit(X_train=X_train, y_train=y_train,\r\n",
    "           **automl_settings)\r\n",
    "# Predict\r\n",
    "# print(automl.predict_proba(X_train))\r\n",
    "# Export the best model\r\n",
    "# print(automl.model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[flaml.automl: 10-01 20:21:15] {1432} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 10-01 20:21:15] {1478} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 10-01 20:21:15] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 10-01 20:21:15] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 10-01 20:21:26] {1865} INFO - Estimated sufficient time budget=106914s. Estimated necessary time budget=1940s.\n",
      "[flaml.automl: 10-01 20:21:26] {1938} INFO -  at 10.8s,\testimator lgbm's best error=0.3042,\tbest estimator lgbm's best error=0.3042\n",
      "[flaml.automl: 10-01 20:21:26] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 10-01 20:21:33] {1938} INFO -  at 18.0s,\testimator lgbm's best error=0.2942,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:21:33] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 10-01 20:21:42] {1938} INFO -  at 27.4s,\testimator lgbm's best error=0.2942,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:21:42] {1748} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 10-01 20:21:56] {1938} INFO -  at 40.9s,\testimator lgbm's best error=0.2942,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:21:56] {1748} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 10-01 20:21:57] {1938} INFO -  at 42.5s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:21:57] {1748} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 10-01 20:21:59] {1938} INFO -  at 44.1s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:21:59] {1748} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:01] {1938} INFO -  at 45.6s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:01] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 10-01 20:22:06] {1938} INFO -  at 51.5s,\testimator lgbm's best error=0.2942,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:06] {1748} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:08] {1938} INFO -  at 53.1s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:08] {1748} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:10] {1938} INFO -  at 54.6s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:10] {1748} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:11] {1938} INFO -  at 56.3s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:11] {1748} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:14] {1938} INFO -  at 59.0s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:14] {1748} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:16] {1938} INFO -  at 61.5s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:16] {1748} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:18] {1938} INFO -  at 63.1s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2942\n",
      "[flaml.automl: 10-01 20:22:18] {1748} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 10-01 20:22:33] {1938} INFO -  at 77.9s,\testimator lgbm's best error=0.2867,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:33] {1748} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:34] {1938} INFO -  at 79.5s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:34] {1748} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 10-01 20:22:42] {1938} INFO -  at 87.2s,\testimator lgbm's best error=0.2867,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:42] {1748} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:44] {1938} INFO -  at 88.9s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:44] {1748} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:45] {1938} INFO -  at 90.4s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:45] {1748} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 10-01 20:22:48] {1938} INFO -  at 93.0s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:48] {1748} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:49] {1938} INFO -  at 93.7s,\testimator extra_tree's best error=0.3202,\tbest estimator lgbm's best error=0.2867\n",
      "[flaml.automl: 10-01 20:22:49] {1748} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:50] {1938} INFO -  at 95.5s,\testimator extra_tree's best error=0.2562,\tbest estimator extra_tree's best error=0.2562\n",
      "[flaml.automl: 10-01 20:22:50] {1748} INFO - iteration 22, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:51] {1938} INFO -  at 96.3s,\testimator extra_tree's best error=0.2562,\tbest estimator extra_tree's best error=0.2562\n",
      "[flaml.automl: 10-01 20:22:51] {1748} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:54] {1938} INFO -  at 98.6s,\testimator extra_tree's best error=0.2562,\tbest estimator extra_tree's best error=0.2562\n",
      "[flaml.automl: 10-01 20:22:54] {1748} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:56] {1938} INFO -  at 100.9s,\testimator extra_tree's best error=0.2562,\tbest estimator extra_tree's best error=0.2562\n",
      "[flaml.automl: 10-01 20:22:56] {1748} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:22:59] {1938} INFO -  at 103.6s,\testimator extra_tree's best error=0.2562,\tbest estimator extra_tree's best error=0.2562\n",
      "[flaml.automl: 10-01 20:22:59] {1748} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:23:01] {1938} INFO -  at 106.5s,\testimator extra_tree's best error=0.2443,\tbest estimator extra_tree's best error=0.2443\n",
      "[flaml.automl: 10-01 20:23:01] {1748} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:23:18] {1938} INFO -  at 123.2s,\testimator extra_tree's best error=0.2293,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:18] {1748} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:23:23] {1938} INFO -  at 128.1s,\testimator extra_tree's best error=0.2293,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:23] {1748} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 10-01 20:23:25] {1938} INFO -  at 130.2s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:25] {1748} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 10-01 20:23:28] {1938} INFO -  at 133.4s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:28] {1748} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 10-01 20:23:30] {1938} INFO -  at 135.5s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:30] {1748} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:23:35] {1938} INFO -  at 140.2s,\testimator extra_tree's best error=0.2293,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:35] {1748} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 10-01 20:23:39] {1938} INFO -  at 143.7s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2293\n",
      "[flaml.automl: 10-01 20:23:39] {1748} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 10-01 20:24:13] {1938} INFO -  at 177.8s,\testimator extra_tree's best error=0.2188,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:13] {1748} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 10-01 20:24:15] {1938} INFO -  at 180.1s,\testimator rf's best error=0.3037,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:15] {1748} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 10-01 20:24:17] {1938} INFO -  at 182.0s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:17] {1748} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 10-01 20:24:23] {1938} INFO -  at 188.0s,\testimator rf's best error=0.2702,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:23] {1748} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 10-01 20:24:27] {1938} INFO -  at 191.9s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:27] {1748} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 10-01 20:24:30] {1938} INFO -  at 194.8s,\testimator rf's best error=0.2702,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:30] {1748} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 10-01 20:24:31] {1938} INFO -  at 196.5s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:31] {1748} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 10-01 20:24:34] {1938} INFO -  at 199.6s,\testimator xgboost's best error=0.5000,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:34] {1748} INFO - iteration 42, current learner catboost\n",
      "[flaml.automl: 10-01 20:24:40] {1938} INFO -  at 204.6s,\testimator catboost's best error=0.3142,\tbest estimator extra_tree's best error=0.2188\n",
      "[flaml.automl: 10-01 20:24:40] {2043} INFO - selected model: ExtraTreesClassifier(criterion='entropy', max_features=0.7540240016109981,\n",
      "                     max_leaf_nodes=195, n_estimators=9, n_jobs=-1)\n",
      "[flaml.automl: 10-01 20:25:30] {2104} INFO - retrain extra_tree for 50.2s\n",
      "[flaml.automl: 10-01 20:25:30] {2110} INFO - retrained model: ExtraTreesClassifier(criterion='entropy', max_features=0.7540240016109981,\n",
      "                     max_leaf_nodes=195, n_estimators=9, n_jobs=-1)\n",
      "[flaml.automl: 10-01 20:25:30] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-01 20:25:30] {1540} INFO - Time taken to find the best model: 177.78650546073914\n",
      "[flaml.automl: 10-01 20:25:30] {1551} WARNING - Time taken to find the best model is 89% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}