{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit (conda)"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## Data loading and cleaning"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["%matplotlib inline\r\n","%config InlineBackend.figure_format = 'retina'\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","from bs4 import BeautifulSoup\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","\r\n","import nltk\r\n","from nltk.corpus import stopwords\r\n","from nltk.stem import SnowballStemmer\r\n","from nltk.tokenize import TweetTokenizer\r\n","\r\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.svm import SVC\r\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\r\n","from sklearn.pipeline import make_pipeline, Pipeline\r\n","from sklearn.model_selection import GridSearchCV\r\n","from sklearn.metrics import make_scorer, accuracy_score, f1_score\r\n","from sklearn.metrics import roc_curve, auc\r\n","from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"],"outputs":[],"metadata":{"_uuid":"db376733d0954ea531a81ee31675624c5968706f","_cell_guid":"d5db572f-3b58-42a5-979a-464769d52524","collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","execution_count":2,"source":["data = pd.read_csv(\"../Naive_Bayes/labeledTrainData.tsv\",sep='\\t')\r\n","data.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id  sentiment                                             review\n","0  5814_8          1  With all this stuff going down at the moment w...\n","1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n","2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n","3  3630_4          0  It must be assumed that those who praised this...\n","4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5814_8</td>\n","      <td>1</td>\n","      <td>With all this stuff going down at the moment w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2381_9</td>\n","      <td>1</td>\n","      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7759_3</td>\n","      <td>0</td>\n","      <td>The film starts with a manager (Nicholas Bell)...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3630_4</td>\n","      <td>0</td>\n","      <td>It must be assumed that those who praised this...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9495_8</td>\n","      <td>1</td>\n","      <td>Superbly trashy and wondrously unpretentious 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":2}],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":["## Machine Learning Model"],"metadata":{}},{"cell_type":"markdown","source":["We split the data into training and testing set:"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["y_train=data['sentiment'].values\r\n","x_train=data['review'].values\r\n","train_data,test_data,train_labels,test_labels=train_test_split(x_train,y_train,shuffle=True,test_size=0.25,random_state=42,stratify=y_train)"],"outputs":[],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","execution_count":17,"source":["def tokenize(text): \r\n","    tknzr = TweetTokenizer()\r\n","    return tknzr.tokenize(text)\r\n","\r\n","def stem(doc):\r\n","    return (stemmer.stem(w) for w in analyzer(doc))\r\n","\r\n","en_stopwords = set(stopwords.words(\"english\")) \r\n","\r\n","vectorizer = CountVectorizer(\r\n","    analyzer = 'word',\r\n","    tokenizer = tokenize,\r\n","    lowercase = True,\r\n","    ngram_range=(1, 1),\r\n","    stop_words = en_stopwords)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["We are going to use cross validation and grid search to find good hyperparameters for our SVM model. We need to build a pipeline to don't get features from the validation folds when building each training model."],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"],"outputs":[],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","execution_count":19,"source":["np.random.seed(1)\r\n","\r\n","pipeline_svm = make_pipeline(vectorizer, \r\n","                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\r\n","\r\n","grid_svm = GridSearchCV(pipeline_svm,\r\n","                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \r\n","                    cv = kfolds,\r\n","                    scoring=\"roc_auc\",\r\n","                    verbose=1,   \r\n","                    n_jobs=-1) \r\n","\r\n","grid_svm.fit(train_data, train_labels)\r\n","grid_svm.score(test_data, test_labels)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.best_params_"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.best_score_"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def report_results(model, X, y):\r\n","    pred_proba = model.predict_proba(X)[:, 1]\r\n","    pred = model.predict(X)        \r\n","\r\n","    auc = roc_auc_score(y, pred_proba)\r\n","    acc = accuracy_score(y, pred)\r\n","    f1 = f1_score(y, pred)\r\n","    prec = precision_score(y, pred)\r\n","    rec = recall_score(y, pred)\r\n","    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\r\n","    return result"],"outputs":[],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":["Let's see how the model (with the best hyperparameters) works on the test data:"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["report_results(grid_svm.best_estimator_, X_test, y_test)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def get_roc_curve(model, X, y):\n","    pred_proba = model.predict_proba(X)[:, 1]\n","    fpr, tpr, _ = roc_curve(y, pred_proba)\n","    return fpr, tpr"],"outputs":[],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","execution_count":null,"source":["roc_svm = get_roc_curve(grid_svm.best_estimator_, X_test, y_test)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fpr, tpr = roc_svm\n","plt.figure(figsize=(14,8))\n","plt.plot(fpr, tpr, color=\"red\")\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Roc curve')\n","plt.show()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Let's see if our model has some bias or variance problem ploting its learning curve:"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from sklearn.model_selection import learning_curve\n","\n","train_sizes, train_scores, test_scores = \\\n","    learning_curve(grid_svm.best_estimator_, X_train, y_train, cv=5, n_jobs=-1, \n","                   scoring=\"roc_auc\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n","\n","    plt.figure(figsize=figsize)\n","    plt.title(title)\n","    if ylim is not None:\n","        plt.ylim(*ylim)\n","    plt.xlabel(\"Training examples\")\n","    plt.ylabel(\"Score\")\n","\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    plt.grid()\n","\n","    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                     train_scores_mean + train_scores_std, alpha=0.1,\n","                     color=\"r\")\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n","    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","             label=\"Training score\")\n","    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","             label=\"Cross-validation score\")\n","\n","    plt.legend(loc=\"lower right\")\n","    return plt"],"outputs":[],"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","execution_count":null,"source":["plot_learning_curve(X_train, y_train, train_sizes, \n","                    train_scores, test_scores, ylim=(0.7, 1.01), figsize=(14,6))\n","plt.show()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["It looks like there isn't a big bias or variance problem, but it is clear that our model would work better with more data:. if we can get more labeled data the model performance will increase."],"metadata":{}},{"cell_type":"markdown","source":["## Examples\n","\n","We are going to apply the obtained machine learning model to some example text. If the output is **1** it means that the text has a negative sentiment associated:"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.predict([\"flying with @united is always a great experience\"])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.predict([\"flying with @united is always a great experience. If you don't lose your luggage\"])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.predict([\"I love @united. Sorry, just kidding!\"])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.predict([\"@united very bad experience!\"])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["grid_svm.predict([\"@united very bad experience!\"])"],"outputs":[],"metadata":{}}]}