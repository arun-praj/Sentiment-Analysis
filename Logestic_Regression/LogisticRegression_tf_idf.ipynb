{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import pickle\r\n",
    "\r\n",
    "training_set=pd.read_csv('../dataset/labeledTrainData.tsv',sep='\\t')\r\n",
    "training_set.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# train_test_split\r\n",
    "y_train=training_set['sentiment'].values\r\n",
    "x_train=training_set['review'].values\r\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(x_train,y_train,shuffle=True,\r\n",
    "test_size=0.25,random_state=42,stratify=y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# vectorization | convert text to number\r\n",
    "# LogisticRegression works of number so we need to vectorized the words.\r\n",
    "\r\n",
    "tf=TfidfVectorizer(min_df=10,max_df=0.95,use_idf=True,ngram_range=(1,3))\r\n",
    "\r\n",
    "tf.fit_transform(train_data)\r\n",
    "train_feature_set=tf.transform(train_data) # for train data we can use fit_transfrom also.\r\n",
    "test_feature_set=tf.transform(test_data)\r\n",
    "\r\n",
    "train_feature_set.shape[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "90185"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "classes=np.unique(train_labels)\r\n",
    "print('classes: ',classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "classes:  [0 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Logistic Regression.\r\n",
    "#  Training phase....\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "# classes are 0 and 1 only\r\n",
    "tf_model = LogisticRegression(penalty='l2',C=1,solver = 'liblinear', random_state = 42, max_iter=1000)\r\n",
    "print (\"------------------Training In Progress------------------------\")\r\n",
    "print (\"Training Examples: \",train_data.shape)\r\n",
    "# model.fit(train_data,train_labels)\r\n",
    "tf_model.fit(train_feature_set,train_labels)\r\n",
    "print ('------------------------Training Completed!')\r\n",
    "\r\n",
    "# Testing phase \r\n",
    "y_pred = tf_model.predict(test_feature_set)\r\n",
    "accuracy_score = round(metrics.accuracy_score(test_labels,y_pred),3)\r\n",
    "print(\"Accuracy: \",accuracy_score)\r\n",
    "print(\"F1: \",round(metrics.f1_score(test_labels, y_pred),3))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------Training In Progress------------------------\n",
      "Training Examples:  (18750,)\n",
      "------------------------Training Completed!\n",
      "Accuracy:  0.891\n",
      "F1:  0.892\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# testing\r\n",
    "test=pd.read_csv('../dataset/testData.tsv',sep='\\t')\r\n",
    "Xtest=test.review.values\r\n",
    "Xtest[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Naturally in a film who's main themes are of mortality, nostalgia, and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones. However there is a craftsmanship and completeness to the film which anyone can enjoy. The pace is steady and constant, the characters full and engaging, the relationships and interactions natural showing that you do not need floods of tears to show emotion, screams to show fear, shouting to show dispute or violence to show anger. Naturally Joyce's short story lends the film a ready made structure as perfect as a polished diamond, but the small changes Huston makes such as the inclusion of the poem fit in neatly. It is truly a masterpiece of tact, subtlety and overwhelming beauty.\""
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# test\r\n",
    "test_array = Xtest[0:2]\r\n",
    "test_review = tf.transform(test_array)\r\n",
    "classes = tf_model.predict(test_review)\r\n",
    "for sentence,classes in zip(test_array,classes):\r\n",
    "    print(sentence,':','pos' if classes ==1 else 'neg')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naturally in a film who's main themes are of mortality, nostalgia, and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones. However there is a craftsmanship and completeness to the film which anyone can enjoy. The pace is steady and constant, the characters full and engaging, the relationships and interactions natural showing that you do not need floods of tears to show emotion, screams to show fear, shouting to show dispute or violence to show anger. Naturally Joyce's short story lends the film a ready made structure as perfect as a polished diamond, but the small changes Huston makes such as the inclusion of the poem fit in neatly. It is truly a masterpiece of tact, subtlety and overwhelming beauty. : pos\n",
      "This movie is a disaster within a disaster film. It is full of great action scenes, which are only meaningful if you throw away all sense of reality. Let's see, word to the wise, lava burns you; steam burns you. You can't stand next to lava. Diverting a minor lava flow is difficult, let alone a significant one. Scares me to think that some might actually believe what they saw in this movie.<br /><br />Even worse is the significant amount of talent that went into making this film. I mean the acting is actually very good. The effects are above average. Hard to believe somebody read the scripts for this and allowed all this talent to be wasted. I guess my suggestion would be that if this movie is about to start on TV ... look away! It is like a train wreck: it is so awful that once you know what is coming, you just have to watch. Look away and spend your time on more meaningful content. : neg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# save model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# pickling the vectorizer\r\n",
    "pickle.dump(tf, open('tf_vectorizer.sav', 'wb'))\r\n",
    "# pickling the model\r\n",
    "pickle.dump(tf_model, open('tf_model.sav', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tf_model = pickle.load(open('tf_model.sav','rb'))\r\n",
    "tf_vectorizer = pickle.load(open('tf_vectorizer.sav','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "x = input('Enter a text: ')\r\n",
    "x_transform = tf_vectorizer.transform([x])\r\n",
    "\r\n",
    "print(x,':','pos' if tf_model.predict(x_transform)[0] ==1 else 'neg')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nice dog : pos\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}